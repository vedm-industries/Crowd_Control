import argparse
import cv2
import numpy as np

# Assuming your YOLO model files are in the 'yolo' directory
YOLO_DIR = "yolo"

def load_yolo_model():
    """Loads the YOLO model weights, configuration, and class names.

    Returns:
        tuple: (net, classes)
            - net: The loaded YOLO network.
            - classes: A list of class names for detected objects.
    """

    # Load YOLO network weights
    weights_path = f"{YOLO_DIR}/yolov7.weights"  # Replace with your weights file name
    net = cv2.dnn.readNetFromDarknet(f"{YOLO_DIR}/yolov7.cfg", weights_path)  # Replace with your config file name

    # Load class names
    classes_path = f"{YOLO_DIR}/coco.names"  # Replace with your class names file name
    with open(classes_path, "r") as f:
        classes = [line.strip() for line in f.readlines()]

    return net, classes

def explore_classes(classes):
    """Prints the available YOLO model class names.

    Args:
        classes: A list of class names for detected objects.
    """

    print("Available YOLO Model Classes:")
    for i, class_name in enumerate(classes):
        print(f"{i}. {class_name}")

def detect_objects(image, net, classes, conf_threshold=0.5, nms_threshold=0.4):
    """Detects objects in an image using the loaded YOLO model.

    Args:
        image: The input image as a NumPy array.
        net: The loaded YOLO network.
        classes: A list of class names for detected objects.
        conf_threshold: Minimum confidence threshold for filtering detections (default: 0.5).
        nms_threshold: Non-maximum suppression threshold to prevent overlapping bounding boxes (default: 0.4).

    Returns:
        list: A list of detected objects, where each object is a dictionary with the following keys:
            - class_id: Integer representing the class ID of the detected object.
            - confidence: Float representing the confidence score of the detection.
            - box: List of four integers representing the bounding box coordinates (x_min, y_min, x_max, y_max).
    """

    rows, cols, channels = image.shape
    blob = cv2.dnn.blobFromImage(image, 1.0 / 255, (416, 416), swapRB=True, crop=False)  # Adjust input size based on your model
    net.setInput(blob)

    # Get outputs from three layers (comment out unused layers if needed)
    outputs = net.forward(["output", "output1", "output2"])  # Adjust output layer names based on your model

    # Parse outputs
    boxes = []
    confidences = []
    class_ids = []
    for output in outputs:
        for detection in output:
            scores, class_id = detection[5:]  # Extract class scores and class ID
            if np.max(scores) > conf_threshold:
                center_x = int(detection[0] * cols)
                center_y = int(detection[1] * rows)
                width = int(detection[2] * cols)
                height = int(detection[3] * rows)
                x_min = int(center_x - (width / 2))
                y_min = int(center_y - (height / 2))
                boxes.append([x_min, y_min, width, height])
                confidences.append(float(np.max(scores)))
                class_ids.append(int(class_id))

    # Apply non-maximum suppression
    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)

    # Prepare detected objects data
    detected_objects = []
    for i, idx in enumerate(indices):
        box = boxes[idx]
        x_min, y_min, width, height = box
        class_id = class_ids[idx]
        confidence = confidences[idx]
