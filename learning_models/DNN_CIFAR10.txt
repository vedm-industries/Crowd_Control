import tensorflow as tf
from tensorflow.keras import datasets, layers, models, utils
from tensorflow.keras.optimizers import Adam
from sklearn.utils import shuffle
import matplotlib.pyplot as plt
import numpy as np

(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()
y_train = y_train.reshape(-1,)
y_test = y_test.reshape(-1,)
classes = ["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"]
x_train = x_train / 255.0
x_test = x_test / 255.0

# Define DNN model
dnn = models.Sequential([
  layers.Flatten(input_shape=(32, 32, 3)),
  layers.Dense(128, activation='relu'),
  layers.Dense(64, activation='relu'),
  layers.Dense(10, activation='softmax')
])

# Compile the model
dnn.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
print("\nTraining the DNN model...")
dnn.fit(x_train, y_train, validation_split=0.1, batch_size=10, epochs=15)

# Evaluate the model
print("\nEvaluating the DNN model...")
dnn_test_loss, dnn_test_acc = dnn.evaluate(x_test, y_test)
print("Test accuracy:", dnn_test_acc)

# (Optional) Visualize activations (not applicable to DNNs)
# Since DNNs don't have spatial layers like CNNs, visualizing activations wouldn't be applicable in this case. 
